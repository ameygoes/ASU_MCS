{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "import geopandas as gpd\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/12 14:49:24 WARN Utils: Your hostname, EN4102944L resolves to a loopback address: 127.0.1.1; using 10.218.105.94 instead (on interface eno1)\n",
      "22/09/12 14:49:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /home/local/ASUAD/kchowdh1/.ivy2/cache\n",
      "The jars for the packages stored in: /home/local/ASUAD/kchowdh1/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/media/kchowdh1/fcf87b53-9c62-4c1d-9df2-cb2b83598bea/kanchan/program_files/spark-3.0.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.sedona#sedona-python-adapter-3.0_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b80ad89e-d614-440c-a6cb-68033116cf9b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-python-adapter-3.0_2.12;1.2.0-incubating in central\n",
      "\tfound org.locationtech.jts#jts-core;1.18.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.12.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.12.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.12.2 in central\n",
      "\tfound org.apache.sedona#sedona-core-3.0_2.12;1.2.0-incubating in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.apache.sedona#sedona-sql-3.0_2.12;1.2.0-incubating in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.1.0-25.2 in central\n",
      ":: resolution report :: resolve 348ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.12.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.12.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.2 from central in [default]\n",
      "\torg.apache.sedona#sedona-core-3.0_2.12;1.2.0-incubating from central in [default]\n",
      "\torg.apache.sedona#sedona-python-adapter-3.0_2.12;1.2.0-incubating from central in [default]\n",
      "\torg.apache.sedona#sedona-sql-3.0_2.12;1.2.0-incubating from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.1.0-25.2 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.18.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.locationtech.jts#jts-core;1.18.1 by [org.locationtech.jts#jts-core;1.18.0] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   1   ||   10  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b80ad89e-d614-440c-a6cb-68033116cf9b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 10 already retrieved (0kB/7ms)\n",
      "22/09/12 14:49:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Sedona App\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName).\\\n",
    "    config(\"spark.jars.packages\", \"org.apache.sedona:sedona-python-adapter-3.0_2.12:1.2.0-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Taxi Trips Shape File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_rdd = ShapefileReader.readToGeometryRDD(sc, \"data/taxi_trip/taxi_zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_df = Adapter.toDf(taxi_zone_rdd, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- OBJECTID: string (nullable = true)\n",
      " |-- Shape_Leng: string (nullable = true)\n",
      " |-- Shape_Area: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------------+-------------------+--------------------+----------+--------------------+\n",
      "|            geometry| OBJECTID|         Shape_Leng|         Shape_Area|                zone|LocationID|             borough|\n",
      "+--------------------+---------+-------------------+-------------------+--------------------+----------+--------------------+\n",
      "|POLYGON ((933100....|        1| 1.16357453189e-001| 7.82306788500e-004|Newark Airport   ...|         1|EWR              ...|\n",
      "|MULTIPOLYGON (((1...|        2| 4.33469666790e-001| 4.86634037837e-003|Jamaica Bay      ...|         2|Queens           ...|\n",
      "|POLYGON ((1026308...|        3| 8.43411059012e-002| 3.14414156821e-004|Allerton/Pelham G...|         3|Bronx            ...|\n",
      "|POLYGON ((992073....|        4| 4.35665270921e-002| 1.11871946192e-004|Alphabet City    ...|         4|Manhattan        ...|\n",
      "|POLYGON ((935843....|        5| 9.21464898574e-002| 4.97957489363e-004|Arden Heights    ...|         5|Staten Island    ...|\n",
      "+--------------------+---------+-------------------+-------------------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_df = taxi_zone_df.drop(\"Shape_Leng\")\n",
    "taxi_zone_df = taxi_zone_df.drop(\"Shape_Area\")\n",
    "taxi_zone_df = taxi_zone_df.drop(\"zone\")\n",
    "taxi_zone_df = taxi_zone_df.drop(\"LocationID\")\n",
    "taxi_zone_df = taxi_zone_df.drop(\"borough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- OBJECTID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            geometry| OBJECTID|\n",
      "+--------------------+---------+\n",
      "|POLYGON ((933100....|        1|\n",
      "|MULTIPOLYGON (((1...|        2|\n",
      "|POLYGON ((1026308...|        3|\n",
      "|POLYGON ((992073....|        4|\n",
      "|POLYGON ((935843....|        5|\n",
      "|POLYGON ((966568....|        6|\n",
      "|POLYGON ((1010804...|        7|\n",
      "|POLYGON ((1005482...|        8|\n",
      "|POLYGON ((1043803...|        9|\n",
      "|POLYGON ((1044355...|       10|\n",
      "|POLYGON ((983945....|       11|\n",
      "|POLYGON ((979908....|       12|\n",
      "|POLYGON ((980801....|       13|\n",
      "|POLYGON ((974794....|       14|\n",
      "|POLYGON ((1045882...|       15|\n",
      "|POLYGON ((1048344...|       16|\n",
      "|POLYGON ((1000036...|       17|\n",
      "|POLYGON ((1016019...|       18|\n",
      "|POLYGON ((1060888...|       19|\n",
      "|POLYGON ((1016371...|       20|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+---------------+-------------------+-------------------+------------------+---------+-----------------+-------------------+------------------+------------+------------------+---------+-------+------------------+---------+------------------+\n",
      "|vendor_name|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|      Trip_Distance|          Start_Lon|         Start_Lat|Rate_Code|store_and_forward|            End_Lon|           End_Lat|Payment_Type|          Fare_Amt|surcharge|mta_tax|           Tip_Amt|Tolls_Amt|         Total_Amt|\n",
      "+-----------+--------------------+---------------------+---------------+-------------------+-------------------+------------------+---------+-----------------+-------------------+------------------+------------+------------------+---------+-------+------------------+---------+------------------+\n",
      "|        VTS| 2009-01-04 02:52:00|  2009-01-04 03:02:00|              1| 2.6299999999999999|-73.991956999999999|         40.721567|     null|             null|         -73.993803|40.695922000000003|        CASH|8.9000000000000004|      0.5|   null|                 0|        0|9.4000000000000004|\n",
      "|        VTS| 2009-01-04 03:31:00|  2009-01-04 03:38:00|              3| 4.5499999999999998|-73.982101999999998|40.736289999999997|     null|             null|-73.955849999999998|40.768030000000003|      Credit|              12.1|      0.5|   null|                 2|        0|              14.6|\n",
      "|        VTS| 2009-01-03 15:43:00|  2009-01-03 15:57:00|              5|              10.35|-74.002587000000005|40.739747999999999|     null|             null|-73.869983000000005|40.770225000000003|      Credit|23.699999999999999|        0|   null|4.7400000000000002|        0|28.440000000000001|\n",
      "|        DDS| 2009-01-01 20:52:58|  2009-01-01 21:14:00|              1|                  5|-73.974266999999998|40.790954999999997|     null|             null|-73.996557999999993|40.731848999999997|      CREDIT|              14.9|      0.5|   null|3.0499999999999998|        0|18.449999999999999|\n",
      "|        DDS| 2009-01-24 16:18:23|  2009-01-24 16:24:56|              1|0.40000000000000002|-74.001580000000004|40.719382000000003|     null|             null|-74.008377999999993|40.720350000000003|        CASH|3.7000000000000002|        0|   null|                 0|        0|3.7000000000000002|\n",
      "+-----------+--------------------+---------------------+---------------+-------------------+-------------------+------------------+---------+-----------------+-------------------+------------------+------------+------------------+---------+-------+------------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.read.format(\"csv\").option(\"delimiter\",\",\").option(\"header\",\"true\").load(\"data/taxi_trip/yellow_tripdata_2009-01.csv\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          Start_Lon|         Start_Lat|\n",
      "+-------------------+------------------+\n",
      "|-73.991956999999999|         40.721567|\n",
      "|-73.982101999999998|40.736289999999997|\n",
      "|-74.002587000000005|40.739747999999999|\n",
      "|-73.974266999999998|40.790954999999997|\n",
      "|-74.001580000000004|40.719382000000003|\n",
      "+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tripDf = tripDf.select(\"Trip_Pickup_DateTime\", \"Start_Lon\", \"Start_Lat\", \"Passenger_Count\", \"Trip_Distance\", \"Fare_Amt\")\n",
    "tripDf = spark.sql(\"select Start_Lon, Start_Lat from trip_df\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Latitude and Longitude to Point Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           point_loc|\n",
      "+--------------------+\n",
      "|POINT (40.721567 ...|\n",
      "|POINT (40.73629 -...|\n",
      "|POINT (40.739748 ...|\n",
      "|POINT (40.790955 ...|\n",
      "|POINT (40.719382 ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.sql(\"select ST_Point(double(trip_df.Start_Lat), double(trip_df.Start_Lon)) as point_loc from trip_df\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Distance Between Point and Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           point_loc|\n",
      "+--------------------+\n",
      "|POINT (40.721567 ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.sql(\"select * from trip_df limit 1\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_df.createOrReplaceTempView(\"taxi_zone_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            geometry|           point_loc|          distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|POLYGON ((933100....|POINT (40.721567 ...| 950259.1074797178|\n",
      "|MULTIPOLYGON (((1...|POINT (40.721567 ...|1031073.0581317813|\n",
      "|POLYGON ((1026308...|POINT (40.721567 ...|1053750.8730177905|\n",
      "|POLYGON ((992073....|POINT (40.721567 ...|1009158.1687323012|\n",
      "|POLYGON ((935843....|POINT (40.721567 ...| 938507.1175333005|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.sql(\"select taxi_zone_df.geometry, trip_df.point_loc, ST_Distance(taxi_zone_df.geometry, trip_df.point_loc) as distance from taxi_zone_df, trip_df\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+--------------------+\n",
      "|            geometry|           point_loc|          distance|            centroid|\n",
      "+--------------------+--------------------+------------------+--------------------+\n",
      "|POLYGON ((933100....|POINT (40.721567 ...| 950259.1074797178|POINT (935996.821...|\n",
      "|MULTIPOLYGON (((1...|POINT (40.721567 ...|1031073.0581317813|POINT (1031085.71...|\n",
      "|POLYGON ((1026308...|POINT (40.721567 ...|1053750.8730177905|POINT (1026452.61...|\n",
      "|POLYGON ((992073....|POINT (40.721567 ...|1009158.1687323012|POINT (990633.980...|\n",
      "|POLYGON ((935843....|POINT (40.721567 ...| 938507.1175333005|POINT (931871.370...|\n",
      "+--------------------+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.sql(\"select geometry, point_loc, distance, ST_Centroid(geometry) as centroid from trip_df\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------------+------------------+\n",
      "|            geometry|           point_loc|            centroid|          distance| centroid_distance|\n",
      "+--------------------+--------------------+--------------------+------------------+------------------+\n",
      "|POLYGON ((933100....|POINT (40.721567 ...|POINT (935996.821...| 950259.1074797178| 955336.1746068312|\n",
      "|MULTIPOLYGON (((1...|POINT (40.721567 ...|POINT (1031085.71...|1031073.0581317813|1044021.1757055434|\n",
      "|POLYGON ((1026308...|POINT (40.721567 ...|POINT (1026452.61...|1053750.8730177905|1057454.4648067043|\n",
      "|POLYGON ((992073....|POINT (40.721567 ...|POINT (990633.980...|1009158.1687323012|1011186.2926528396|\n",
      "|POLYGON ((935843....|POINT (40.721567 ...|POINT (931871.370...| 938507.1175333005| 942401.4134977745|\n",
      "+--------------------+--------------------+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDf = spark.sql(\"select geometry, point_loc, centroid, distance, ST_Distance(point_loc, centroid) as centroid_distance from trip_df\")\n",
    "tripDf.createOrReplaceTempView(\"trip_df\")\n",
    "tripDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
